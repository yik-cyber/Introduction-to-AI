###<center>实验报告</center>  

**数据预处理**： 
```
未处理的数据为国家名命名的txt文件，文件中按行存储该国的名字样本
对数据进行预处理，得到catetory_lines，其中的每一个元素是存储对应index国家的名字字符串列表；all_categories是国家名字符串列表；n_categories是国家数目。
```  
**模型描述**：  
生成序列模型  
```
主要参数为category和start_letter，通过model返回一个output，再将output中最大对数概率下标对应新字符加入name，重新生成新字符的input_line_tensor，继续迭代，直到生成到一个EOF或到达max_line
```
训练过程  
```
每次迭代随机选出一个国家的一个名字，并生成category_line_tensor, input_line_tensor, target_line_tensor，将其放入训练模型。训练模型用对于input中的每一个字符进行损失计算，具体过程为通过将category_tensor, input_line_tensor[i], hidden放入model中得到output和hidden，然后用output和target_line_tensor[i]通过nn的NLLLoss()计算损失，再进行参数更新，返回output和平均损失。
```
具体的神经网络模型  
```
1. input_combined = (category, input, hidden)  
2. i2h = W1 * input_combined  
3. i2o = W2 * input_combined  
4. output_combined = (i2h, i2o)  
5. out_put = W3 * output_combined  
6. output = softmax(out_put)  
return output, hidden(for the next iteration)  
```
**训练结果**
参数设置参考main.py  
生成样例  
```
Country: Russian
Raner    Uaner    Saner
Country: German
Garerer  Earerer  Ranerer
Country: Spanish
Sara     Para     Aoran
Country: Chinese
Can      Han      Iang
```
损失下降图示  
![image](figure_1.png)


**问题思考**  
question1
```
个人想法是在输入中引入更多信息，不仅是输入的字符，还包括国家和上一个hidden，国家引入了种类信息，hidden引入了时序信息。
``` 
question2  
```
对给出的样例进行求解。此时我们只需要利用网络进行输出，网络传播时不会进行求导和传播，也不会有dropout的影响。
```
quetion3
```
根据utils.py中的代码，设置EOS marker可以标记生成的序列末尾，如果不设置序列的生成过程会一直持续，如果只设置了
了max_length生成的序列长度也都会一样。
```
**心得感想**  
最大的体会是对于问题解决模型的设计，此次lab将序列的单个字符进行输入，预测下一个出现概率最大的字符，最终得到一个序列。训练方式则采用了神经网络，并且在神经网络内部通过将category和hidden拼接到输入向量上，引入更多的信息。
